{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"pretrained_model\": \"bert-base-cased\",\n",
    "    \"tokenizer\": \"bert-base-cased\",\n",
    "    \"max_seq_length\": 512,\n",
    "    \"batch_size\": 10,\n",
    "    \"lr\": 2e-5,\n",
    "    \"epochs\": 10,\n",
    "    \"device\": \"cuda\",\n",
    "    \"gpu_ids\": \"2\",\n",
    "    \"seed\": 2020,\n",
    "    \"fp16\": False,\n",
    "    \"loss_scale\": 0,\n",
    "    \"gradient_accumulation_steps\":1,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_labels\": 4,\n",
    "    \"is_multilabel\": False,\n",
    "    \"valid_metric\": \"macro_f1\",\n",
    "    \"model_save_dir\": \"../checkpoints/bert_cased_512_biocaster_4cate_20200903/\",\n",
    "    \"result_file\":\"../results/bert_biocaster_202009091.csv\",\n",
    "    \"patience\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from beta_nlp.utils.data_util import biocaster2df,split_data\n",
    "data_file = \"/home/zm324/workspace/doc_cls/datasets/biocaster/BioCaster.3.xml\"\n",
    "data_df = biocaster2df(data_file)\n",
    "train_set,dev_set,test_set = split_data(data_df,config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    ata_df = biocaster2df(data_file)\n",
    "    train_set,dev_set,test_set = split_data(data_df,config[\"seed\"])\n",
    "    from beta_nlp.models.bert_cls import BertModel\n",
    "    from beta_nlp.utils.common import save_to_csv\n",
    "    cls = BertModel(config)\n",
    "    cls.train(train_set,dev_set)\n",
    "    result = cls.test(test_set)\n",
    "    result.update(config)\n",
    "    save_to_csv(result, config[\"result_file\"])\n",
    "    del cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config[\"model\"] = \"BERT\"\n",
    "pretrained_model_opt= [\"bert-base-uncased\"]\n",
    "max_seq_length_opt = [256,512]\n",
    "lr_opt = [5e-5, 3e-5, 2e-5]\n",
    "for i in range(10):\n",
    "    for lr in lr_opt:\n",
    "        for max_seq_length in max_seq_length_opt:\n",
    "            for pretrained_model in pretrained_model_opt:\n",
    "                if pretrained_model== \"bert-base-cased\" or max_seq_length>500:\n",
    "                    config[\"batch_size\"] = 8\n",
    "                else:\n",
    "                    config[\"batch_size\"] = 16\n",
    "                config[\"lr\"]=lr\n",
    "                config[\"max_seq_length\"] = max_seq_length\n",
    "                config[\"pretrained_model\"] = pretrained_model\n",
    "                config[\"model_save_dir\"] = \"../checkpoints/\"+\"bert_\"+pretrained_model+str(max_seq_length)+\"_\"+str(lr)\n",
    "                train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_cls",
   "language": "python",
   "name": "doc_cls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
